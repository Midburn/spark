# /****************************************************************************
#                            DATABASE CONFIGURATIONS
# ****************************************************************************/
#
# At the moment we support 2 types of db clients: sqlite3 and MySQL.
#
# sqlite3:
#
# sqlite3 is a simple filebase database. It's nice and simple for dev work
# but for dev work only. It's recommended to simply use MySQL, but sqlite
# is still supported.
#
# In order to run Spark with sqlite3, uncomment the following lines:
#
# ------------ UNCOMMENT THE FOLLOWING LINES TO CONFIGURE SQLITE3 -------------
#
# # sqlite3 configs
# SPARK_DB_CLIENT=sqlite3
# SPARK_DB_FILENAME=./dev.sqlite3
#
# -------------- UNCOMMENT THE ABOVE LINES TO CONFIGURE SQLITE3 ---------------
#
# MySQL:
#
# MySQL is a relational database service used everywhere. The following are
# the configuration needed to set Spark to use the correct database on the
# correct host.
#
#
# ------------- UNCOMMENT THE FOLLOWING LINES TO CONFIGURE MYSQL --------------
#
# # mysql configs
# SPARK_DB_CLIENT=mysql
# SPARK_DB_HOSTNAME=localhost
# SPARK_DB_DBNAME=spark
# SPARK_DB_USER=spark
# SPARK_DB_PASSWORD=spark
# SPARK_DB_DEBUG=false
#
# --------------- UNCOMMENT THE ABOVE LINES TO CONFIGURE MYSQL ----------------

# /****************************************************************************
#                           SPARK APP CONFIGURATIONS
# ****************************************************************************/

# SERVER CONFIGURATIONS
SPARK_SERVER_PORT=3000
SPARK_SERVER_HOSTNAME=localhost
SPARK_SERVER_PROTOCOL=http
SPARK_SERVER_URL=http://localhost:3000

# MAIL CONFIGURATIONS
SPARK_MAILSERVER_ENABLE=true
SPARK_MAILSERVER_FROM=spark@localhost
SPARK_MAILSERVER_HOST=localhost
SPARK_MAILSERVER_PORT=25
SPARK_MAILSERVER_METHOD=SMTP
SPARK_MAILSERVER_SECURE_CONNECTION=false
# optional user / password for authentication to mailserver
SPARK_MAILSERVER_USER=""
SPARK_MAILSERVER_PASSWORD=""

# PAYMENTS CONFIGURATIONS
SPARK_ICREDIT_URL=
SPARK_ICREDIT_PRIVATETOKEN=

# FACEBOOK APP INTEGRATION
SPARK_FACEBOOK_APP=1083906121721925
SPARK_FACEBOOK_SECRET=
SPARK_FACEBOOK_CALLBACK=http://localhost:3000

SPARK_RECAPTCHA_IGNORE=false
SPARK_RECAPTCHA_SITEKEY=""
SPARK_RECAPTCHA_SECRETKEY=""

# DRUPAL PROFILES SYSTEM
DRUPAL_PROFILE_API_URL=
DRUPAL_PROFILE_API_USER=
DRUPAL_PROFILE_API_PASSWORD=
DRUPAL_TICKET_SYNC_EVERY_X_MINUTES=

# VOLUNTEER ENV
VOLUNTEERS_BASE_URL=


# TODO - Temporary credential to call the spark API - change in production
SPARK_SECRET_TOKEN=YWxseW91bmVlZGlzbG92ZWFsbHlvdW5lZWRpc2xvdmVsb3ZlbG92ZWlzYWxseW91

#Opbeat integration
OPBEAT_APP_ID=""
OPBEAT_ORGANIZATION_ID=""
OPBEAT_SECRET_TOKEN=""

#supported Languges
LANGUAGES=["en","he"]

#gate
GATE_FORCE_ENTRY_PASSWORD=""

# optional - devops / slack / travis / deployment
# better to export these variables as they might be used from shell scripts
# if you have ssh access to the staging environment you can get the values from there (/opt/spark/.env)
export SLACK_API_TOKEN=""
export SLACK_LOG_WEBHOOK=""
export TRAVIS_PULL_REQUEST="false"
export TRAVIS_REPO_SLUG="Midburn/Spark"
export TRAVIS_BRANCH="master"
export TRAVIS_BUILD_NUMBER="666"
export TRAVIS_BUILD_ID="666666666"
export SPARK_DEPLOYMENT_KEY=""
export SPARK_DEPLOYMENT_HOST="ubuntu@sparkstaging.midburn.org"


